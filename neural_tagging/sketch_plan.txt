For a first article a choice has to be made whether to focus it on methodology or on philological-linguistic issues:

I envisage the methodology-variant including a detailed description of how my system of LCS annotations works (esp. regarding the identification and marking of morphological innovations, and also how to deal with annoyances like doublet-forms, badly-integrated foreign loans, insecure etymologies etc.), how it can be automated using the Autoreconstructor and automatic tagging/lemmatisation, and then finishing with a case-study on applying these things to Assemanianus, with just some very shallow demonstration of what data can be extracted from a text that has been largely automatically processed in this way (similar to what Rabus etc. did at the end of that 2021 paper on autotagging the Å½itie Evfimija Velikogo, where they basically just pulled out all the aorists vs imperfects from the text and compared their ratio to some other similar texts. I can already do similarly shallow things even with Assemanianus as badly auto-tagged as it currently is (i.e. find many of the nasal-spellings of the PRAP masc/nt. N.sg. short forms, or find the very nearly flawless preservation of PV2/3 /dz/ < *g. The problem of course is that Diels may well already have listed all of these things in one of his copious footnotes).
If I did this option the section on automatic tagging/lemmatisation would have to include at least an attempt to improve on the current ways of doing this; I've read the UD-pipeline paper and it seems to supercede Rabus/Scherrer's 2017 LSTM paper, but it would be impossible for me to reimplement since the UD pipeline is written from scratch in C++ by clearly very serious and knowledgeable programmers, whereas all I could feasibly do is use PyTorch (Rabus/Scherrer use something called DyNet which I think is a framework similar to PyTorch but from an era before neural-network machine-learning became as ubiquitous as it is now and thus before PyTorch came to dominate and make it all easy). Lemmatisation is another big issue because UD Pipeline does it by basically inferring sets of string-manipulations that transform surface-forms to their lemmas from the training data, and then learning which of these rules to apply to each word in the course of training (it lists over 1700 separate rules for OCS, and that is based only on PROIEL, i.e. Marianus). I tried pasting some of Assemanianus into their web-interface processer and it can make up non-existent lemmas as a result of applying these rules, and for autoreconstruction only lemmas in my reconstructed-list are useful anyway, so this type of lemmatisation probably isn't useful for me at all. The point is I don't think I am ever going to be able to improve upon the neural-network architecture that UD Pipeline uses; what I could do though is much more sensibly normalise all the data and retrain it, though I'd have to use the CONLL or whatever format and I don't know exactly how compatible they are with your tags (I would prefer not to use any kind of lossy conversion).


